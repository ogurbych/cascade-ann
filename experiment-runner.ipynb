{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e9c9d9-3413-4a71-8e45-254dadccbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826879cf-a6ce-4576-bce1-b77d623165b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df: pd.DataFrame, n: int = 2) -> list:\n",
    "    return np.array_split(df, n)\n",
    "\n",
    "\n",
    "def blend_and_split(df: pd.DataFrame, n: int = 2, frac: int = 0.5, seed: int = 42) -> list:\n",
    "    return list(df.sample(frac=frac, replace=False, random_state=seed) for i in range(0, n))\n",
    "\n",
    "\n",
    "def init_svm():\n",
    "    return SVR(kernel=\"rbf\")\n",
    "\n",
    "\n",
    "def init_sgd():\n",
    "    return SGDRegressor(loss='squared_loss', alpha=0.0001)\n",
    "\n",
    "\n",
    "def init_dnn():\n",
    "    # TODO: implement\n",
    "    raise Exception(f'Not implemented')\n",
    "\n",
    "\n",
    "def init_model(model_type):\n",
    "    \"\"\"\n",
    "    :param model_type: 'svm', 'sgd', 'neural_network'\n",
    "    :return: model instance\n",
    "    \"\"\"\n",
    "    # вибір типу та ініціалізація моделі\n",
    "    if model_type == 'svm':\n",
    "        model = init_svm()\n",
    "    elif model_type == 'sgd':\n",
    "        model = init_sgd()\n",
    "    elif model_type == 'dnn':\n",
    "        model = init_dnn()\n",
    "    else:\n",
    "        raise Exception(f'Unknown model type: {model_type}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_metrics():\n",
    "    return {\n",
    "        'train': {\n",
    "            'explained_variance_score': [],\n",
    "            'max_error': [],\n",
    "            'mean_absolute_error': [],\n",
    "            'mean_squared_error': [],\n",
    "            'root_mean_squared_error': [],\n",
    "            'mean_absolute_percentage_error': [],\n",
    "            'median_absolute_error': [],\n",
    "            'r2_score': []\n",
    "        },\n",
    "        'test': {\n",
    "            'explained_variance_score': [],\n",
    "            'max_error': [],\n",
    "            'mean_absolute_error': [],\n",
    "            'mean_squared_error': [],\n",
    "            'root_mean_squared_error': [],\n",
    "            'mean_absolute_percentage_error': [],\n",
    "            'median_absolute_error': [],\n",
    "            'r2_score': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def calc_train_metrics(metrics, train_y, train_pred):\n",
    "    metrics['train']['explained_variance_score'].append(explained_variance_score(train_y, train_pred))\n",
    "    metrics['train']['max_error'].append(max_error(train_y, train_pred))\n",
    "    metrics['train']['mean_absolute_error'].append(mean_absolute_error(train_y, train_pred))\n",
    "    metrics['train']['mean_squared_error'].append(mean_squared_error(train_y, train_pred, squared=True))\n",
    "    metrics['train']['root_mean_squared_error'].append(mean_squared_error(train_y, train_pred, squared=False))\n",
    "    metrics['train']['mean_absolute_percentage_error'].append(mean_absolute_percentage_error(train_y, train_pred))\n",
    "    metrics['train']['median_absolute_error'].append(median_absolute_error(train_y, train_pred))\n",
    "    metrics['train']['r2_score'].append(r2_score(train_y, train_pred))\n",
    "    \n",
    "    \n",
    "def calc_test_metrics(metrics, test_y, test_pred):\n",
    "    metrics['test']['explained_variance_score'].append(explained_variance_score(test_y, test_pred))\n",
    "    metrics['test']['max_error'].append(max_error(test_y, test_pred))\n",
    "    metrics['test']['mean_absolute_error'].append(mean_absolute_error(test_y, test_pred))\n",
    "    metrics['test']['mean_squared_error'].append(mean_squared_error(test_y, test_pred, squared=True))\n",
    "    metrics['test']['root_mean_squared_error'].append(mean_squared_error(test_y, test_pred, squared=False))\n",
    "    metrics['test']['mean_absolute_percentage_error'].append(mean_absolute_percentage_error(test_y, test_pred))\n",
    "    metrics['test']['median_absolute_error'].append(median_absolute_error(test_y, test_pred))\n",
    "    metrics['test']['r2_score'].append(r2_score(test_y, test_pred))\n",
    "    \n",
    "    \n",
    "def get_scaler(scaler_type):\n",
    "    \"\"\"\n",
    "    :param scaler_type: 'max_abs_scaler',\n",
    "                        'min_max_scaler',\n",
    "                        'standard_scaler'\n",
    "    :return: scaler instance\n",
    "    \"\"\"\n",
    "    # вибір типу та ініціалізація скейлеру\n",
    "    if scaler_type == 'max_abs_scaler':\n",
    "        return MaxAbsScaler()\n",
    "    elif scaler_type == 'min_max_scaler':\n",
    "        return MinMaxScaler()\n",
    "    elif scaler_type == 'standard_scaler':\n",
    "        return StandardScaler()\n",
    "    else:\n",
    "        raise Exception(f'Unknown scaler type: {scaler_type}')\n",
    "    \n",
    "    \n",
    "def scale(scaler_type, train_X, test_X):\n",
    "    scaler = get_scaler(scaler_type)\n",
    "    \n",
    "    scaler.fit(train_X)\n",
    "\n",
    "    train_X = pd.DataFrame(scaler.transform(train_X))\n",
    "    test_X = pd.DataFrame(scaler.transform(test_X))\n",
    "\n",
    "    return train_X, test_X\n",
    "\n",
    "\n",
    "def add_poly_features(poly, train_X, test_X):\n",
    "    train_X = pd.DataFrame(poly.fit_transform(train_X))\n",
    "    test_X  = pd.DataFrame(poly.fit_transform(test_X))\n",
    "\n",
    "    return train_X, test_X\n",
    "\n",
    "\n",
    "def print_pretty(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('\\t' * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            print_pretty(value, indent+1)\n",
    "        else:\n",
    "            print('\\t' * (indent+2) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f77a67-50f4-41ea-9112-14757740f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_type:      str,  # 'svm', 'sgd', 'dnn'\n",
    "                   scaler_type:     str,  # 'max_abs_scaler', 'min_max_scaler', or 'standard_scaler'\n",
    "                   train_datasets:  list,\n",
    "                   test_dataset:    pd.DataFrame,\n",
    "                   n_pfeatures:     int,  # 0 -> do not generate polynomial features\n",
    "                   export_to_excel: bool=True,\n",
    "                   keep_last:       bool=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Note: number of cascades is set implicitly by the number of train data sets\n",
    "    \"\"\"\n",
    "    if n_pfeatures > 0:\n",
    "        poly = PolynomialFeatures(n_pfeatures)\n",
    "    test_preds = []\n",
    "    metrics = init_metrics()\n",
    "    models = []\n",
    "\n",
    "    for cascade in range(len(train_datasets)):\n",
    "        print(f'cascade-{cascade}')\n",
    "        train_dataset = train_datasets[cascade].copy()\n",
    "        test_dataset_loc = test_dataset.copy()\n",
    "        train_X = train_dataset.iloc[:, :-1]\n",
    "        train_y = train_dataset.iloc[:,-1]\n",
    "        test_X = test_dataset_loc.iloc[:, :-1]\n",
    "        test_y = test_dataset_loc.iloc[:,-1]\n",
    "        test_y_hist = test_dataset_loc.iloc[:,-1]\n",
    "        model = init_model(model_type)\n",
    "        \n",
    "        # генеруємо і додаємо y_pred_i до фіч\n",
    "        for i in range(cascade):\n",
    "            train_X_alt = train_X.copy()\n",
    "            test_X_alt = test_X.copy()\n",
    "            \n",
    "            if n_pfeatures > 0:\n",
    "                train_X_alt, test_X_alt = add_poly_features(poly, train_X_alt, test_X_alt)\n",
    "            train_X_alt, test_X_alt = scale(scaler_type, train_X_alt, test_X_alt)\n",
    "            \n",
    "            if keep_last:\n",
    "                train_X['y_pred'] = models[i].predict(train_X_alt)\n",
    "                test_X['y_pred'] = models[i].predict(test_X_alt)\n",
    "            else:\n",
    "                train_X[f'y_pred_{i+1}'] = models[i].predict(train_X_alt)\n",
    "                test_X[f'y_pred_{i+1}'] = models[i].predict(test_X_alt)\n",
    "        \n",
    "        if n_pfeatures > 0:\n",
    "            train_X, test_X = add_poly_features(poly, train_X, test_X)\n",
    "        train_X, test_X = scale(scaler_type, train_X, test_X)\n",
    "        \n",
    "        model.fit(train_X, train_y)\n",
    "        models.append(model)\n",
    "\n",
    "        # рахуємо та зберігаємо метрики\n",
    "        test_pred = model.predict(test_X)\n",
    "        calc_train_metrics(metrics, train_y, model.predict(train_X))\n",
    "        calc_test_metrics(metrics, test_y, test_pred)\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    if export_to_excel:\n",
    "        date_time_now = datetime.datetime.now()\n",
    "        metrics_train_df = pd.DataFrame(data=metrics['train'])\n",
    "        metrics_train_df.index.name = 'cascade'\n",
    "        metrics_test_df = pd.DataFrame(data=metrics['test'])\n",
    "        metrics_test_df.index.name = 'cascade'\n",
    "        test_preds_df = pd.DataFrame(data=test_preds)\n",
    "        \n",
    "        with pd.ExcelWriter(f'experiment-run-{date_time_now}.xlsx') as writer:  \n",
    "            metrics_train_df.to_excel(writer, sheet_name='train')\n",
    "            metrics_test_df.to_excel(writer, sheet_name='test')\n",
    "            test_preds_df.T.to_excel(writer, sheet_name='test-preds')\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ade51a-2475-4e8d-aa46-65dddb1abcec",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd4fc16-6864-4ed1-903b-114aa8961f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('trainCO.txt', header=None)\n",
    "df_test = pd.read_csv('testCO.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3846001-9a7e-47a5-8d4d-01bb280821f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.8641072872723247]\n",
      "\tmax_error\n",
      "\t\t\t[11.193751251320936]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.2912024398238739]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.2874305608552335]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.5361255084914665]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.23830794305338163]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.18285042966583626]\n",
      "\tr2_score\n",
      "\t\t\t[0.8641066412569429]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.885743912346448]\n",
      "\tmax_error\n",
      "\t\t\t[8.465705486392427]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.29024988998542706]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.24917312780718937]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.4991724429565292]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.2127678185805919]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.1862377301771625]\n",
      "\tr2_score\n",
      "\t\t\t[0.885736063415919]\n"
     ]
    }
   ],
   "source": [
    "train_X = df_train.iloc[:, :-1]\n",
    "train_y = df_train.iloc[:,-1]\n",
    "test_X = df_test.iloc[:, :-1]\n",
    "test_y = df_test.iloc[:,-1]\n",
    "\n",
    "metrics = init_metrics()\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X, test_X = add_poly_features(poly, train_X, test_X)\n",
    "train_X, test_X = scale('max_abs_scaler', train_X, test_X)\n",
    "model = init_model('sgd')\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "calc_train_metrics(metrics, train_y, model.predict(train_X))\n",
    "calc_test_metrics(metrics, test_y, model.predict(test_X))\n",
    "\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88fa2d-d9e6-47bf-820f-c43f5c96b9d0",
   "metadata": {},
   "source": [
    "## Plain Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2be97e4-8b60-4883-a5c4-7f1b6d1c6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_split_plain: 3\n",
      "cascade-0\n",
      "cascade-1\n",
      "cascade-2\n",
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9316064900330141, 0.9046907339228347, 0.712472152415087]\n",
      "\tmax_error\n",
      "\t\t\t[1.9168546236285504, 4.060536642367351, 11.171609093902006]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.2451589958536199, 0.3224565780128606, 0.4260550361194906]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.10906777475897275, 0.23829204589219088, 0.6425013262017842]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.3302541063468746, 0.48815166279773226, 0.801561804355587]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.18040336332097365, 0.2540939001716105, 0.39162180967196214]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.1890412375290786, 0.2259221748724669, 0.24706029695258752]\n",
      "\tr2_score\n",
      "\t\t\t[0.9316051539136831, 0.9045083909988478, 0.7124718000138446]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.7320473276240136, 0.8531792119822312, 0.8519342041309947]\n",
      "\tmax_error\n",
      "\t\t\t[8.251200801984085, 8.371420250058634, 8.24808904859765]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.6002981161730295, 0.36516409790515414, 0.3599220823870297]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.7723474242566778, 0.3224422813001446, 0.3232729060440067]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.8788329899683317, 0.5678400138244438, 0.5685709331684189]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.40713289181843426, 0.276266569807263, 0.2576052036100789]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.39058857801745783, 0.2625880174922622, 0.2448793638917608]\n",
      "\tr2_score\n",
      "\t\t\t[0.6458227342459155, 0.8521368467509236, 0.8517559451107947]\n",
      "CPU times: user 483 ms, sys: 507 ms, total: 990 ms\n",
      "Wall time: 520 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_split_plain = split(df_train, n=3)\n",
    "\n",
    "print('len train_split_plain:', len(train_split_plain))\n",
    "\n",
    "metrics = run_experiment(model_type = 'sgd', # TODO: 'dnn'\n",
    "                         scaler_type = 'max_abs_scaler',\n",
    "                         train_datasets = train_split_plain,\n",
    "                         test_dataset = df_test,\n",
    "                         n_pfeatures = 0)\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3d18f-7cfc-498f-9e47-23703feab8e3",
   "metadata": {},
   "source": [
    "## Blended Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70874cb3-ac21-41bc-9a2e-8548275e11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_split_blended: 3\n",
      "cascade-0\n",
      "cascade-1\n",
      "cascade-2\n",
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.8686069324115232, 0.8696635741485539, 0.8721661471808148]\n",
      "\tmax_error\n",
      "\t\t\t[10.602040129740487, 10.612289851115175, 10.612374321059443]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.33817728021416166, 0.3365323961725474, 0.3321187766289172]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.2770750883296699, 0.27484449692544444, 0.2695776720231015]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.5263792248271867, 0.5242561367551595, 0.519208697946309]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.26926678356641387, 0.268022862322063, 0.26443116684119977]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.23622927977639718, 0.23661962615826382, 0.23724629343914283]\n",
      "\tr2_score\n",
      "\t\t\t[0.86860562835843, 0.8696634179912481, 0.872161048336731]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.862875332393821, 0.8637953235350101, 0.8661707747020093]\n",
      "\tmax_error\n",
      "\t\t\t[8.392203030098235, 8.402915159160147, 8.408299862270015]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.34398371543287853, 0.34238411463414103, 0.33792162474411136]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.299045798282255, 0.29705985481585634, 0.2919137980900074]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.5468508007512242, 0.5450319759572426, 0.5402904756610164]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.2565015866664567, 0.25557752578641935, 0.252179564589963]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.23545278392210933, 0.23700511303690786, 0.23464894377713608]\n",
      "\tr2_score\n",
      "\t\t\t[0.8628658297491036, 0.8637765287490364, 0.8661363686906673]\n"
     ]
    }
   ],
   "source": [
    "train_split_blended = blend_and_split(df_train, n=3, frac=.8)\n",
    "\n",
    "print('len train_split_blended:', len(train_split_blended))\n",
    "\n",
    "metrics = run_experiment(model_type = 'sgd',\n",
    "                         scaler_type = 'max_abs_scaler',\n",
    "                         train_datasets = train_split_blended,\n",
    "                         test_dataset = df_test,\n",
    "                         n_pfeatures = 0)\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694d412-9bd8-46da-83a2-167607482e79",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903bc8e8-786f-4028-bba3-1ee1d842adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('procom_train.csv', header=None)\n",
    "df_test = pd.read_csv('procom_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b07c5b-0068-4be0-b059-675cc5898c3c",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd598a4-a570-4be5-bd19-c3da9ede4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9436456683428726]\n",
      "\tmax_error\n",
      "\t\t\t[77705.49057470186]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[18583.867179830315]\n",
      "\tmean_squared_error\n",
      "\t\t\t[552319238.6434243]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[23501.4731164543]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.04572135611756515]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[15780.236797051504]\n",
      "\tr2_score\n",
      "\t\t\t[0.9434624380713165]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9377792882474798]\n",
      "\tmax_error\n",
      "\t\t\t[101608.10019069718]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[17918.881338531148]\n",
      "\tmean_squared_error\n",
      "\t\t\t[607538056.7433652]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[24648.287095523803]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.04427424528974683]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[13982.254209578357]\n",
      "\tr2_score\n",
      "\t\t\t[0.9358699888451765]\n"
     ]
    }
   ],
   "source": [
    "train_X = df_train.iloc[:, :-1]\n",
    "train_y = df_train.iloc[:,-1]\n",
    "test_X = df_test.iloc[:, :-1]\n",
    "test_y = df_test.iloc[:,-1]\n",
    "\n",
    "metrics = init_metrics()\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X, test_X = add_poly_features(poly, train_X, test_X)\n",
    "train_X, test_X = scale('max_abs_scaler', train_X, test_X)\n",
    "model = init_model('sgd')\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "calc_train_metrics(metrics, train_y, model.predict(train_X))\n",
    "calc_test_metrics(metrics, test_y, model.predict(test_X))\n",
    "\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e6a39-6002-45dd-8c12-ab3b46c9cc28",
   "metadata": {},
   "source": [
    "## Plain Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04ddbe99-8664-432f-83be-8b6fb2a22708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_split_plain: 3\n",
      "cascade-0\n",
      "cascade-1\n",
      "cascade-2\n",
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9501799528052095, 0.9544311687493802, 0.9662693323612902]\n",
      "\tmax_error\n",
      "\t\t\t[73175.26949329441, 61369.27049331536, 70796.45578583912]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[14103.713704901214, 16709.213983221936, 14405.019242923867]\n",
      "\tmean_squared_error\n",
      "\t\t\t[374374613.8874479, 456468911.8974759, 336112905.7050629]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[19348.76259318533, 21365.133088690927, 18333.382276739416]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.039492135460351734, 0.039628875851587385, 0.03498999476179775]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[8849.576666942798, 12358.14030767235, 11766.982053210842]\n",
      "\tr2_score\n",
      "\t\t\t[0.9501786108264616, 0.9544311550612986, 0.9662692453040648]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.8851937232056044, 0.8527712229557596, 0.9255301542080799]\n",
      "\tmax_error\n",
      "\t\t\t[106921.01702784572, 107394.57331118739, 112633.94981808099]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[27643.603605281227, 42813.6477058302, 22098.837950500856]\n",
      "\tmean_squared_error\n",
      "\t\t\t[1310824961.5376503, 2698653878.848142, 834915260.8137177]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[36205.31675786928, 51948.569555360635, 28894.90025616489]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.06395425173998256, 0.10752722212955089, 0.054029442558625414]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[21059.21998578121, 38266.879612159624, 17708.086629465848]\n",
      "\tr2_score\n",
      "\t\t\t[0.8616329981762106, 0.7151376750269247, 0.911868689714143]\n",
      "CPU times: user 103 ms, sys: 6.24 ms, total: 109 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_split_plain = split(df_train, n=3)\n",
    "\n",
    "print('len train_split_plain:', len(train_split_plain))\n",
    "\n",
    "metrics = run_experiment(model_type = 'sgd',\n",
    "                         scaler_type = 'max_abs_scaler',\n",
    "                         train_datasets = train_split_plain,\n",
    "                         test_dataset = df_test,\n",
    "                         n_pfeatures = 0)\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbae1b3-6337-4410-a2bf-b73546487d27",
   "metadata": {},
   "source": [
    "## Blended Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31bd411-4424-4167-bb9e-1cc4bdc9415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_split_blended: 4\n",
      "cascade-0\n",
      "cascade-1\n",
      "cascade-2\n",
      "cascade-3\n",
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9401162638428308, 0.9405113014109258, 0.9384894270738083, 0.936995181458762]\n",
      "\tmax_error\n",
      "\t\t\t[70855.54527165386, 69584.66947078641, 69993.51629091066, 71773.22716971562]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[18244.552201973544, 18202.009012348233, 18557.410708821502, 18851.79387462468]\n",
      "\tmean_squared_error\n",
      "\t\t\t[551899720.1852795, 547488867.7208946, 565757276.3775729, 582227947.5255094]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[23492.546055829698, 23398.48003014073, 23785.652742306083, 24129.400065594447]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.04434011200651712, 0.04420150882749385, 0.045009048200635136, 0.04557351494502158]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[14613.314930532564, 15061.470451993664, 15957.76921090926, 15579.257400357805]\n",
      "\tr2_score\n",
      "\t\t\t[0.9399765816088499, 0.9404562963708768, 0.938469463806852, 0.9366781492811557]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9243918154924121, 0.9240177095514208, 0.9225970117862633, 0.9212269583066688]\n",
      "\tmax_error\n",
      "\t\t\t[111444.26480228943, 112884.38604687783, 113863.81140063488, 115429.67201177322]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[19755.546585486736, 19890.14650046293, 20079.21734121606, 20448.58641556847]\n",
      "\tmean_squared_error\n",
      "\t\t\t[717659527.0922503, 721699252.9607469, 734900851.9395553, 752847392.0623437]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[26789.168092575223, 26864.46077926648, 27109.054796129563, 27438.06465591813]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.049377131443049255, 0.04987059465354688, 0.050353268816545664, 0.050988698599829595]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[15170.69756365128, 16056.246579240484, 15936.650402224914, 16379.950241396524]\n",
      "\tr2_score\n",
      "\t\t\t[0.924245875683089, 0.9238194535649458, 0.9224259298500518, 0.9205315434729511]\n"
     ]
    }
   ],
   "source": [
    "train_split_blended = blend_and_split(df_train, n=4, frac=.8)\n",
    "\n",
    "print('len train_split_blended:', len(train_split_blended))\n",
    "\n",
    "metrics = run_experiment(model_type = 'sgd',\n",
    "                         scaler_type = 'max_abs_scaler',\n",
    "                         train_datasets = train_split_blended,\n",
    "                         test_dataset = df_test,\n",
    "                         n_pfeatures = 2)\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684c8bb-10e4-4017-802a-16ae1a4149a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
